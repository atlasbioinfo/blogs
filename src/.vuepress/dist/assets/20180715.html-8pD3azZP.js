import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{r as s,o as d,c,a as t,f as e,b as i,e as l}from"./app-B3mr5nDC.js";const r={},o=l('<p>昨天配置好GPU加速敲开心，开始跑我的小模型。结果惊奇的发现CPU效率比GPU高5倍多，这是什么鬼？和群里各个大佬讨论了一下，最终发现是BatchSize的问题，在此顺便讨论一下在模型训练过程中BatchSize的设置。</p><blockquote><ul><li>Show一下硬件和我简陋的小模型</li><li>不同Size下GPU和CPU的运算时间</li><li>到底需要设置多大的Size？</li></ul></blockquote><hr><p>先简单说一下我理解的Batch Size吧。</p><p>比如你有1w个数据（或者图片）需要训练，也就是需要找1w个数据的规律（感觉深度学习就是让模型找规律）。这时候有几种策略：</p><ol><li>全部数据都拿来用，一次性找所有的规律。</li></ol><p>这个首先就是很难（很费时间）总结他们的规律，类似“众口难调”，全局学习速率也不好定。其次就是，往往内存很难容纳全局那么大的数据量。全部数据都拿来用也叫Batch Gradient Descent，批梯度下降，就是每次都用全部数据找规律。</p><ol start="2"><li>每次就拿一个数据来找规律。</li></ol><p>这个就会造成模型很难收敛，类似“公说公有理，婆说婆有理”。这样是不可取的=-=</p><ol start="3"><li>因此就诞生了mini-batches</li></ol><p>就是把数据总量分为n份，每次找一份的规律，一轮把每一份的规律找一遍。而Batch Size参数就是每一份有多少数据的意思，比如Batch Size=1000，那么1w的数据就被分成10份，这个意思。</p><p><strong>很多大佬的博客写的超级好，我也是看完之后才能总结出上面这些，详细请看：</strong></p>',12),p={href:"https://blog.csdn.net/u010402786/article/details/51188876",target:"_blank",rel:"noopener noreferrer"},g={href:"https://blog.csdn.net/ycheng_sjtu/article/details/49804041",target:"_blank",rel:"noopener noreferrer"},h=l(`<h2 id="show一下硬件和我简陋的小模型" tabindex="-1"><a class="header-anchor" href="#show一下硬件和我简陋的小模型"><span>Show一下硬件和我简陋的小模型</span></a></h2><p>首先说一下我的模型，我的测试模型很简单，就是6层全连接层，每层64个unit，激活函数用relu，最后加个BN层。训练集总量135844。</p><p>计算的硬件如下，CPU是i7-3770:</p><div class="language-txt line-numbers-mode" data-ext="txt" data-title="txt"><pre class="language-txt"><code>CPU

	Intel(R) Core(TM) i7-3770 CPU @ 3.40GHz

	基准速度:	3.40 GHz
	插槽:	1
	内核:	4
	逻辑处理器:	8
	虚拟化:	已启用
	L1 缓存:	256 KB
	L2 缓存:	1.0 MB
	L3 缓存:	8.0 MB

	利用率	5%
	速度	3.15 GHz
	正常运行时间	0:23:56:01
	进程	188
	线程	2579
	句柄	83109
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>GPU是GTX 1060 6G版本：</p><div class="language-txt line-numbers-mode" data-ext="txt" data-title="txt"><pre class="language-txt"><code>GPU 0
	NVIDIA GeForce GTX 1060 6GB

	驱动程序版本:	22.21.13.8554
	驱动程序日期:	09/01/2017
	DirectX 版本:	12 (FL 12.1)
	物理位置：	PCI 总线 1、设备 0、功能 0

	利用率	2%
	专用 GPU 内存	0.2/6.0 GB
	共享 GPU 内存	0.0/12.0 GB
	GPU 内存	0.2/18.0 GB
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="不同size下gpu和cpu的运算时间" tabindex="-1"><a class="header-anchor" href="#不同size下gpu和cpu的运算时间"><span>不同Size下GPU和CPU的运算时间</span></a></h2><p>Epoch定50次，改变不同的Batch Size。</p><p>这个是CPU运行情况：</p><figure><img src="https://pic.atlasbioinfo.com/CPURun.PNG" alt="CPURun" tabindex="0" loading="lazy"><figcaption>CPURun</figcaption></figure><p>这个是GPU运行情况：</p><figure><img src="https://pic.atlasbioinfo.com/GPURun.PNG" alt="GPURun" tabindex="0" loading="lazy"><figcaption>GPURun</figcaption></figure><p>其实，感叹一下，GPU加速还是对CNN效果更明显，我这个模型和数据量对GTX1060来说还是有点弱。</p><p>下面数字是程序开始和程序结束的时间，代码是：</p><div class="language-python line-numbers-mode" data-ext="py" data-title="py"><pre class="language-python"><code><span class="token keyword">from</span> time <span class="token keyword">import</span> time
timeBeg<span class="token operator">=</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#中间是程序</span>
timeEnd<span class="token operator">=</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token punctuation">(</span>timeEnd<span class="token operator">-</span>timeBeg<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>结果为：</p><table><thead><tr><th style="text-align:left;">Epoch</th><th style="text-align:center;">100</th><th style="text-align:center;">500</th><th style="text-align:center;">1000</th><th style="text-align:center;">2000</th><th style="text-align:center;">3000</th><th style="text-align:center;">4000</th><th style="text-align:center;">5000</th><th style="text-align:center;">6000</th><th style="text-align:center;">7000</th><th style="text-align:center;">8000</th><th style="text-align:center;">9000</th><th style="text-align:center;">10000</th><th style="text-align:center;">135844</th></tr></thead><tbody><tr><td style="text-align:left;">CPU</td><td style="text-align:center;">128.1</td><td style="text-align:center;">75.1</td><td style="text-align:center;">60.5</td><td style="text-align:center;">54.3</td><td style="text-align:center;">50.8</td><td style="text-align:center;">51.0</td><td style="text-align:center;">54.0</td><td style="text-align:center;">53.3</td><td style="text-align:center;">54.5</td><td style="text-align:center;">53.1</td><td style="text-align:center;">53.1</td><td style="text-align:center;">52.6</td><td style="text-align:center;">69.0</td></tr><tr><td style="text-align:left;">GPU</td><td style="text-align:center;">522.1</td><td style="text-align:center;">134.5</td><td style="text-align:center;">85.0</td><td style="text-align:center;">60.9</td><td style="text-align:center;">51.5</td><td style="text-align:center;">47.0</td><td style="text-align:center;">44.8</td><td style="text-align:center;">44.4</td><td style="text-align:center;">42.5</td><td style="text-align:center;">40.1</td><td style="text-align:center;">40.2</td><td style="text-align:center;">39.7</td><td style="text-align:center;">35.2</td></tr><tr><td style="text-align:left;">CPU/GPU</td><td style="text-align:center;">0.2</td><td style="text-align:center;">0.6</td><td style="text-align:center;">0.7</td><td style="text-align:center;">0.9</td><td style="text-align:center;">1.0</td><td style="text-align:center;">1.1</td><td style="text-align:center;">1.2</td><td style="text-align:center;">1.2</td><td style="text-align:center;">1.3</td><td style="text-align:center;">1.3</td><td style="text-align:center;">1.3</td><td style="text-align:center;">1.3</td><td style="text-align:center;">2.0</td></tr><tr><td style="text-align:left;">GPU/CPU</td><td style="text-align:center;">4.1</td><td style="text-align:center;">1.8</td><td style="text-align:center;">1.4</td><td style="text-align:center;">1.1</td><td style="text-align:center;">1.0</td><td style="text-align:center;">0.9</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.8</td><td style="text-align:center;">0.5</td></tr></tbody></table><p>做个折线图：</p><figure><img src="https://pic.atlasbioinfo.com/GPUCPUSpeed.png" alt="GPUCPUSpeed" tabindex="0" loading="lazy"><figcaption>GPUCPUSpeed</figcaption></figure><p>可以看到，Size为100时，CPU的效率时GPU的4倍，而Size为总数据量时，GPU效率是CPU的2倍。</p><p>对于GTX 1060有<strong>1280个CUDA核心</strong>，i7-3770 是<strong>4核8线程</strong>。</p><p>所以非常非常粗略的证明了，Batch-Size大于显卡核心数可以发挥显卡的最大功能。</p><p>额，确实粗略，主要结论足够了，方案欠缺点见下：</p><ol><li>对于每个Epoch应做几个重复，取均值和方差减少随机误差；</li><li>GTX1060显卡和早它1年多的i7 3770相比，这两个不同的东西是否有可比性？</li><li>每个核心的计算量应该也做个梯度（比如增大模型层数等）</li></ol><p>这样才比较完善，不过懒得做了=-=</p><p>上面的证明过程也可以用我之前举得大力士和小学生的栗子来说明：</p><p>8个大力士类似CPU，跑的快力气大；1280个小学生类似GPU，跑的慢力气小；</p><p>如果都让他们去送信，一次只给他们100封送，大力士跑得快效率占优，小学生也就100个忙活，其他都闲的没事做；而让他们一次去送1280封信，小学生虽然跑的慢，但是一轮全部送完，大力士跑的快但是得送N多次。就是这个到理。</p><p>对了，实际中设置Batch Size大小最好设置为2的次方数，比如256，512等，据说能快很多。</p><h2 id="到底需要设置多大的size" tabindex="-1"><a class="header-anchor" href="#到底需要设置多大的size"><span>到底需要设置多大的Size？</span></a></h2><p>问题来了，到底需要设置多大的Size？</p><p>这个，首先作为“工程学”的深度学习，肯定是哪个准确率高，Precision和Recall都好，ROC和PR都优秀，就用哪个呗。</p><p>不过通过经验和网上大佬评测：</p>`,33),u={href:"https://blog.csdn.net/ycheng_sjtu/article/details/49804041",target:"_blank",rel:"noopener noreferrer"},m=t("blockquote",null,[t("ul",null,[t("li",null,"随着 Batch_Size 增大，处理相同数据量的速度越快。"),t("li",null,"随着 Batch_Size 增大，达到相同精度所需要的 epoch 数量越来越多。"),t("li",null,"由于上述两种因素的矛盾， Batch_Size 增大到某个时候，达到时间上的最优。"),t("li",null,"由于最终收敛精度会陷入不同的局部极值，因此 Batch_Size 增大到某些时候，达到最终收敛精度上的最优。")])],-1),y=t("p",null,"突然发现像我这种数据，量不大的，做深度学习，完全可以全部加载去找最优值啊~",-1),x=t("figure",null,[t("img",{src:"https://pic.atlasbioinfo.com/logo.png",alt:"博主简介",tabindex:"0",loading:"lazy"}),t("figcaption",null,"博主简介")],-1);function v(b,P){const n=s("ExternalLinkIcon");return d(),c("div",null,[o,t("p",null,[t("strong",null,[t("a",p,[e("机器学习中常见问题_几种梯度下降法"),i(n)])]),t("strong",null,[t("a",g,[e("谈谈深度学习中的 Batch_Size"),i(n)])])]),h,t("p",null,[e("以下引用："),t("a",u,[e("谈谈深度学习中的 Batch_Size"),i(n)])]),m,y,x])}const G=a(r,[["render",v],["__file","20180715.html.vue"]]),S=JSON.parse('{"path":"/posts/AI/20180715.html","title":"深度学习训练过程中BatchSize的设置","lang":"zh-CN","frontmatter":{"icon":"robot","date":"2018-07-15T00:00:00.000Z","title":"深度学习训练过程中BatchSize的设置","categories":["AI"],"description":"昨天配置好GPU加速敲开心，开始跑我的小模型。结果惊奇的发现CPU效率比GPU高5倍多，这是什么鬼？和群里各个大佬讨论了一下，最终发现是BatchSize的问题，在此顺便讨论一下在模型训练过程中BatchSize的设置。 Show一下硬件和我简陋的小模型 不同Size下GPU和CPU的运算时间 到底需要设置多大的Size？ 先简单说一下我理解的Batc...","head":[["meta",{"property":"og:url","content":"https://blog.atlasbioinfo.com/posts/AI/20180715.html"}],["meta",{"property":"og:site_name","content":"ATLAS生物信息博客"}],["meta",{"property":"og:title","content":"深度学习训练过程中BatchSize的设置"}],["meta",{"property":"og:description","content":"昨天配置好GPU加速敲开心，开始跑我的小模型。结果惊奇的发现CPU效率比GPU高5倍多，这是什么鬼？和群里各个大佬讨论了一下，最终发现是BatchSize的问题，在此顺便讨论一下在模型训练过程中BatchSize的设置。 Show一下硬件和我简陋的小模型 不同Size下GPU和CPU的运算时间 到底需要设置多大的Size？ 先简单说一下我理解的Batc..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://pic.atlasbioinfo.com/CPURun.PNG"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-03-20T11:04:46.000Z"}],["meta",{"property":"article:author","content":"Haopeng Yu"}],["meta",{"property":"article:published_time","content":"2018-07-15T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2024-03-20T11:04:46.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"深度学习训练过程中BatchSize的设置\\",\\"image\\":[\\"https://pic.atlasbioinfo.com/CPURun.PNG\\",\\"https://pic.atlasbioinfo.com/GPURun.PNG\\",\\"https://pic.atlasbioinfo.com/GPUCPUSpeed.png\\",\\"https://pic.atlasbioinfo.com/logo.png\\"],\\"datePublished\\":\\"2018-07-15T00:00:00.000Z\\",\\"dateModified\\":\\"2024-03-20T11:04:46.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Haopeng Yu\\",\\"url\\":\\"https://github.com/atlasbioinfo\\"}]}"]]},"headers":[{"level":2,"title":"Show一下硬件和我简陋的小模型","slug":"show一下硬件和我简陋的小模型","link":"#show一下硬件和我简陋的小模型","children":[]},{"level":2,"title":"不同Size下GPU和CPU的运算时间","slug":"不同size下gpu和cpu的运算时间","link":"#不同size下gpu和cpu的运算时间","children":[]},{"level":2,"title":"到底需要设置多大的Size？","slug":"到底需要设置多大的size","link":"#到底需要设置多大的size","children":[]}],"git":{"createdTime":1710932686000,"updatedTime":1710932686000,"contributors":[{"name":"hyu","email":"hp.yu@outlook.com","commits":1}]},"readingTime":{"minutes":5.07,"words":1522},"filePathRelative":"posts/AI/20180715.md","localizedDate":"2018年7月15日","excerpt":"<p>昨天配置好GPU加速敲开心，开始跑我的小模型。结果惊奇的发现CPU效率比GPU高5倍多，这是什么鬼？和群里各个大佬讨论了一下，最终发现是BatchSize的问题，在此顺便讨论一下在模型训练过程中BatchSize的设置。</p>\\n<blockquote>\\n<ul>\\n<li>Show一下硬件和我简陋的小模型</li>\\n<li>不同Size下GPU和CPU的运算时间</li>\\n<li>到底需要设置多大的Size？</li>\\n</ul>\\n</blockquote>\\n<hr>\\n<p>先简单说一下我理解的Batch Size吧。</p>\\n<p>比如你有1w个数据（或者图片）需要训练，也就是需要找1w个数据的规律（感觉深度学习就是让模型找规律）。这时候有几种策略：</p>","autoDesc":true}');export{G as comp,S as data};
